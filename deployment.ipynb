{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a90f7865-8fe3-458d-bdad-80c5811b4922",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T14:36:09.564123Z",
     "iopub.status.busy": "2025-07-18T14:36:09.563802Z",
     "iopub.status.idle": "2025-07-18T14:36:09.567007Z",
     "shell.execute_reply": "2025-07-18T14:36:09.566509Z",
     "shell.execute_reply.started": "2025-07-18T14:36:09.564103Z"
    }
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "from sagemaker import get_execution_role\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "43560f4f-6785-465c-9c9a-4dbe90ac7234",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T14:36:10.123100Z",
     "iopub.status.busy": "2025-07-18T14:36:10.122520Z",
     "iopub.status.idle": "2025-07-18T14:36:10.250874Z",
     "shell.execute_reply": "2025-07-18T14:36:10.250364Z",
     "shell.execute_reply.started": "2025-07-18T14:36:10.123079Z"
    }
   },
   "outputs": [],
   "source": [
    "role = sagemaker.get_execution_role()  # auto-fills execution role\n",
    "bucket = 'sagemaker-us-east-1-xxxx'  # change this\n",
    "model_key = 'model.tar.gz'   # change if you uploaded to a subfolder\n",
    "model_uri = f's3://{bucket}/{model_key}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f11b0b3a-fb84-4dfe-ac62-b6981af7b7c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T14:36:10.864937Z",
     "iopub.status.busy": "2025-07-18T14:36:10.864371Z",
     "iopub.status.idle": "2025-07-18T14:39:44.705591Z",
     "shell.execute_reply": "2025-07-18T14:39:44.705103Z",
     "shell.execute_reply.started": "2025-07-18T14:36:10.864917Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch import PyTorchModel\n",
    "from sagemaker import get_execution_role\n",
    "import sagemaker\n",
    "\n",
    "role = get_execution_role()\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "model = PyTorchModel(\n",
    "    model_data='s3://sagemaker-us-east-1-xxxx/model.tar.gz',\n",
    "    role=role,\n",
    "    entry_point='inference.py',\n",
    "    source_dir='model/code',\n",
    "    framework_version='1.12.1',\n",
    "    py_version='py38',\n",
    ")\n",
    "\n",
    "predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m5.large',\n",
    "    endpoint_name='xxxx.xxxx'     # name endpoint\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f725697d-c4a6-4f7f-b69f-1723286a155c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T14:39:44.706709Z",
     "iopub.status.busy": "2025-07-18T14:39:44.706445Z",
     "iopub.status.idle": "2025-07-18T14:39:45.040349Z",
     "shell.execute_reply": "2025-07-18T14:39:45.039823Z",
     "shell.execute_reply.started": "2025-07-18T14:39:44.706691Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class index: b'{\"predicted_class\": 0, \"confidence\": 1.0}'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from sagemaker.predictor import Predictor\n",
    "import io\n",
    "\n",
    "# 1. Load your real image (replace with your image path)\n",
    "img_path = 'aeroplane.jpg'  # or .png etc.\n",
    "image = Image.open(img_path).convert(\"RGB\")  # ensure it's RGB\n",
    "\n",
    "# 2. Define preprocessing transform (resize + normalize like CIFAR-10)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),  # resize to CIFAR-10 size\n",
    "    transforms.ToTensor(),  # convert to torch tensor (C, H, W)\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # normalize to [-1, 1]\n",
    "])\n",
    "\n",
    "# 3. Apply transform and convert to numpy array\n",
    "image_tensor = transform(image)\n",
    "img_array = image_tensor.unsqueeze(0).numpy()  # add batch dim, shape = (1, 3, 32, 32)\n",
    "\n",
    "# 4. Convert to bytes for x-npy format\n",
    "npy_bytes = io.BytesIO()\n",
    "np.save(npy_bytes, img_array)\n",
    "npy_bytes.seek(0)\n",
    "\n",
    "# 5. Create Predictor and send request\n",
    "predictor = Predictor(endpoint_name='xxxx.xxxx')  # your deployed endpoint name\n",
    "\n",
    "response = predictor.predict(npy_bytes.read(), {\n",
    "    \"ContentType\": \"application/x-npy\",\n",
    "    \"Accept\": \"application/json\"\n",
    "})\n",
    "\n",
    "# 6. Output the prediction\n",
    "print(\"Predicted class index:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4cd41f-6d46-4ffe-a20b-eb06cb5a10bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
